"""
Core tests for adaptive prompt sizing feature - focused test suite.

Tests the essential functionality of the adaptive prompt sizing feature
with minimal setup and maximum coverage of the key behaviors.
"""

import pytest
from vibe_check.tools.legacy.review_pr_monolithic_backup import PRReviewTool


class TestAdaptivePromptSizingCore:
    """Core tests for adaptive prompt sizing."""

    def test_summary_content_creation_basic(self):
        """Test basic summary content creation functionality."""
        pr_tool = PRReviewTool()

        # Create minimal test data for summary content creation
        pr_data = {
            "metadata": {
                "number": 123,
                "title": "Test PR",
                "author": "test-user",
                "created_at": "2025-06-01T12:00:00Z",
                "head_branch": "test-branch",
                "base_branch": "main",
                "body": "Test PR description",
            },
            "statistics": {"files_count": 10, "additions": 500, "deletions": 200},
            "diff": "test diff content",
            "files": [{"path": "src/test.py", "additions": 100, "deletions": 50}],
            "comments": [],
            "linked_issues": [],
        }

        review_context = {
            "is_re_review": False,
            "review_count": 0,
            "previous_reviews": [],
        }

        # Test summary content creation
        summary_content = pr_tool._create_summary_data_content(pr_data, review_context)

        # Verify basic structure
        assert "PR #123 Review Data (Large PR - Summary Analysis)" in summary_content
        assert "Test PR" in summary_content
        assert "test-user" in summary_content
        assert "**Files Changed:** 10" in summary_content
        assert "**Lines:** +500/-200" in summary_content
        assert "src/test.py: +100/-50" in summary_content
        assert "Large PR Analysis Note" in summary_content
        assert "50k character prompt limit" in summary_content

    def test_diff_pattern_extraction_basic(self):
        """Test basic diff pattern extraction functionality."""
        pr_tool = PRReviewTool()

        # Create test diff with multiple lines
        test_diff = "\n".join(
            [
                "diff --git a/file1.py b/file1.py",
                "index abc123..def456 100644",
                "--- a/file1.py",
                "+++ b/file1.py",
                "@@ -1,5 +1,8 @@",
                " def function():",
                "-    old_code()",
                "+    new_code()",
                "+    additional_code()",
                " # More lines here",
            ]
            + [f"+ Line {i}" for i in range(200)]
        )  # Add many lines

        # Extract patterns with limit
        extracted = pr_tool._extract_diff_patterns(test_diff, 10)

        # Should be limited
        lines = extracted.split("\n")
        assert len(lines) <= 10

        # Should contain key diff indicators
        assert any("diff --git" in line for line in lines)

    def test_adaptive_timeout_calculation_basic(self):
        """Test basic adaptive timeout calculation."""
        pr_tool = PRReviewTool()

        # Test different content sizes
        small_timeout = pr_tool._calculate_adaptive_timeout(10000, 42)
        large_timeout = pr_tool._calculate_adaptive_timeout(60000, 42)

        # Larger content should get longer timeout
        assert large_timeout >= small_timeout

        # Should be reasonable values
        assert 60 <= small_timeout <= 600
        assert 60 <= large_timeout <= 600

    def test_summary_content_size_reduction(self):
        """Test that summary content is actually smaller than original."""
        pr_tool = PRReviewTool()

        # Create realistic large diff with mixed content (not all pattern lines)
        large_diff_lines = []
        for i in range(2000):
            if i % 10 == 0:
                large_diff_lines.append(f"+ Added line {i}")  # Pattern line
            elif i % 10 == 1:
                large_diff_lines.append(f"- Removed line {i}")  # Pattern line
            else:
                large_diff_lines.append(f"  Context line {i}")  # Non-pattern line
        large_diff = "\n".join(large_diff_lines)

        pr_data = {
            "metadata": {
                "number": 456,
                "title": "Large PR for testing",
                "author": "developer",
                "created_at": "2025-06-01T12:00:00Z",
                "head_branch": "large-feature",
                "base_branch": "main",
                "body": "A large PR with lots of changes",
            },
            "statistics": {"files_count": 25, "additions": 2000, "deletions": 800},
            "diff": large_diff,
            "files": [
                {"path": f"src/file_{i}.py", "additions": 80, "deletions": 32}
                for i in range(25)
            ],
            "comments": [],
            "linked_issues": [],
        }

        review_context = {
            "is_re_review": False,
            "review_count": 0,
            "previous_reviews": [],
        }

        # Create summary content
        summary = pr_tool._create_summary_data_content(pr_data, review_context)

        # Summary should be reasonable size (not trying to include the full 50k diff)
        # The summary uses _extract_diff_patterns which limits the diff content
        assert len(summary) < 30000  # Should be much smaller than the 50k original

        # But should still contain essential information
        assert "Large PR for testing" in summary
        assert "src/file_0.py: +80/-32" in summary
        assert len(summary) > 1000  # Should still be substantial

    def test_file_statistics_format_accuracy(self):
        """Test that file statistics are formatted correctly."""
        pr_tool = PRReviewTool()

        pr_data = {
            "metadata": {
                "number": 789,
                "title": "File stats test",
                "author": "tester",
                "created_at": "2025-06-01T12:00:00Z",
                "head_branch": "test",
                "base_branch": "main",
                "body": "Testing file statistics",
            },
            "statistics": {"files_count": 3, "additions": 300, "deletions": 100},
            "diff": "test diff",
            "files": [
                {"path": "src/main.py", "additions": 150, "deletions": 50},
                {"path": "tests/test_main.py", "additions": 100, "deletions": 30},
                {"path": "README.md", "additions": 50, "deletions": 20},
            ],
            "comments": [],
            "linked_issues": [],
        }

        review_context = {
            "is_re_review": False,
            "review_count": 0,
            "previous_reviews": [],
        }

        summary = pr_tool._create_summary_data_content(pr_data, review_context)

        # Check that file statistics are accurate
        assert "src/main.py: +150/-50" in summary
        assert "tests/test_main.py: +100/-30" in summary
        assert "README.md: +50/-20" in summary

    def test_max_prompt_size_constant(self):
        """Test that the 50k threshold is correctly applied in the code."""
        # This is testing the constant used in the actual implementation
        # We can verify it by checking that the logic would trigger at 50k

        test_content_under = "a" * 49999  # Just under 50k
        test_content_over = "a" * 50001  # Just over 50k

        assert len(test_content_under) < 50000
        assert len(test_content_over) > 50000

        # The actual logic check happens in _run_claude_analysis
        # but we can verify the threshold concept works
